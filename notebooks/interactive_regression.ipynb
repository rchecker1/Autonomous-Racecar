{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Releasing all cameras...\n",
      "Found camera objects: ['CSICamera', 'JetRacerCamera']\n",
      "‚úì Stopped CSICamera.running\n",
      "‚úì Deleted CSICamera\n",
      "‚úì Stopped JetRacerCamera.running\n",
      "Warning cleaning JetRacerCamera: JetRacerCamera.stop() missing 1 required positional argument: 'self'\n",
      "‚úì Garbage collection completed\n",
      "‚è≥ Waiting for camera hardware to release...\n",
      "‚úÖ Camera release complete!\n",
      "GST_ARGUS: Creating output stream\n",
      "CONSUMER: Waiting until producer is connected...\n",
      "GST_ARGUS: Available Sensor modes :\n",
      "GST_ARGUS: 3280 x 2464 FR = 21.000000 fps Duration = 47619048 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 3280 x 1848 FR = 28.000001 fps Duration = 35714284 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 1920 x 1080 FR = 29.999999 fps Duration = 33333334 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 1640 x 1232 FR = 29.999999 fps Duration = 33333334 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 1280 x 720 FR = 59.999999 fps Duration = 16666667 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: Running with following settings:\n",
      "   Camera index = 0 \n",
      "   Camera mode  = 4 \n",
      "   Output Stream W = 1280 H = 720 \n",
      "   seconds to Run    = 0 \n",
      "   Frame Rate = 59.999999 \n",
      "GST_ARGUS: Setup Complete, Starting captures for 0 seconds\n",
      "GST_ARGUS: Starting repeat capture requests.\n",
      "CONSUMER: Producer has connected; continuing.\n",
      "‚úì JetRacer camera created in 'training' mode\n",
      "‚úì Will resize from 640x480 to 224x224\n",
      "Starting JetRacer camera...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@6.256] global cap_gstreamer.cpp:1728 open OpenCV | GStreamer warning: Cannot query video position: status=0, value=-1, duration=-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Camera started successfully\n",
      "‚úì Raw image shape: (480, 640, 3)\n",
      "‚úì Processed image shape: (224, 224, 3)\n",
      "‚úÖ Camera initialized successfully!\n",
      "Resolution: 224x224\n",
      "Mode: training\n",
      "‚úÖ Capturing images: (224, 224, 3)\n",
      "üéØ Camera ready for use!\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Clean slate\n",
    "from jetracer.camera_utils import JetRacerCamera, release_cam\n",
    "import time\n",
    "\n",
    "# Step 2: Release any existing cameras\n",
    "release_cam()\n",
    "time.sleep(2)\n",
    "\n",
    "# Step 3: Create camera for your use case\n",
    "camera = JetRacerCamera('training')  # or 'inference' or 'safe'\n",
    "\n",
    "# Step 4: Start camera with error handling\n",
    "if camera.start():\n",
    "    print(\"‚úÖ Camera initialized successfully!\")\n",
    "    print(f\"Resolution: {camera.width}x{camera.height}\")\n",
    "    print(f\"Mode: {camera.mode}\")\n",
    "    \n",
    "    # Test image capture\n",
    "    img = camera.read()\n",
    "    if img is not None:\n",
    "        print(f\"‚úÖ Capturing images: {img.shape}\")\n",
    "        print(\"üéØ Camera ready for use!\")\n",
    "    else:\n",
    "        print(\"‚ùå Camera not capturing images\")\n",
    "else:\n",
    "    print(\"‚ùå Camera failed to initialize\")\n",
    "    print(\"üîß Try restarting Jupyter kernel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (224, 224, 3)\n",
      "Image type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Get the current frame from camera\n",
    "image = camera.value\n",
    "\n",
    "# Display image info\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "print(f\"Image type: {type(image)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from xy_dataset import XYDataset\n",
    "\n",
    "TASK = 'road_following'\n",
    "\n",
    "CATEGORIES = ['apex']\n",
    "\n",
    "DATASETS = ['A', 'B']\n",
    "\n",
    "TRANSFORMS = transforms.Compose([\n",
    "    transforms.ColorJitter(0.2, 0.2, 0.2, 0.2),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "datasets = {}\n",
    "for name in DATASETS:\n",
    "    datasets[name] = XYDataset(TASK + '_' + name, CATEGORIES, TRANSFORMS, random_hflip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xy_dataset.XYDataset at 0xfffeb176f970>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[DATASETS[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ JETRACER DATA COLLECTION SETUP\n",
      "========================================\n",
      "üîÑ Releasing all cameras...\n",
      "Found camera objects: ['JetRacerCamera']\n",
      "‚úì Stopped JetRacerCamera.running\n",
      "Warning cleaning JetRacerCamera: JetRacerCamera.stop() missing 1 required positional argument: 'self'\n",
      "‚úì Garbage collection completed\n",
      "‚è≥ Waiting for camera hardware to release...\n",
      "‚úÖ Camera release complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error generated. /dvs/git/dirty/git-master_linux/multimedia/nvgstreamer/gst-nvarguscamera/gstnvarguscamerasrc.cpp, execute:805 Failed to create CaptureSession\n",
      "[ WARN:0@227.745] global cap_gstreamer.cpp:1728 open OpenCV | GStreamer warning: Cannot query video position: status=0, value=-1, duration=-1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Could not initialize camera.  Please see error trace.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/jetcam-0.0.0-py3.10.egg/jetcam/csi_camera.py:24\u001b[0m, in \u001b[0;36mCSICamera.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m re:\n\u001b[0;32m---> 24\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not read image from camera.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not read image from camera.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m release_cam()\n\u001b[1;32m     18\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m camera \u001b[38;5;241m=\u001b[39m \u001b[43mJetRacerCamera\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 224x224 for training\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m camera\u001b[38;5;241m.\u001b[39mstart():\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚ùå Camera failed to start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/jetracer-0.0.0-py3.10.egg/jetracer/camera_utils.py:30\u001b[0m, in \u001b[0;36mJetRacerCamera.__init__\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minference\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# Same reliable config for training\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcamera \u001b[38;5;241m=\u001b[39m \u001b[43mCSICamera\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m480\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_fps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m21\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)  \u001b[38;5;66;03m# Resize for model input\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/jetcam-0.0.0-py3.10.egg/jetcam/csi_camera.py:26\u001b[0m, in \u001b[0;36mCSICamera.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not read image from camera.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not initialize camera.  Please see error trace.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     29\u001b[0m atexit\u001b[38;5;241m.\u001b[39mregister(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcap\u001b[38;5;241m.\u001b[39mrelease)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not initialize camera.  Please see error trace."
     ]
    }
   ],
   "source": [
    "# Working JetRacer Data Collection Interface\n",
    "# Run this in your Jupyter notebook\n",
    "\n",
    "import cv2\n",
    "import ipywidgets\n",
    "import threading\n",
    "import time\n",
    "import os\n",
    "import uuid\n",
    "from IPython.display import display, clear_output\n",
    "from jetracer.camera_utils import JetRacerCamera, release_cam\n",
    "\n",
    "print(\"üéØ JETRACER DATA COLLECTION SETUP\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Step 1: Initialize camera\n",
    "release_cam()\n",
    "time.sleep(2)\n",
    "\n",
    "camera = JetRacerCamera('training')  # 224x224 for training\n",
    "if not camera.start():\n",
    "    print(\"‚ùå Camera failed to start\")\n",
    "    exit()\n",
    "\n",
    "print(\"‚úÖ Camera initialized for data collection\")\n",
    "\n",
    "# Step 2: Set up data collection parameters\n",
    "CATEGORIES = ['apex']  # Road following target points\n",
    "DATASETS = ['A', 'B']  # Different data collection sessions\n",
    "\n",
    "# Create data directories\n",
    "base_dir = \"/home/checker/Autonomous-Racecar/data/training_images\"\n",
    "for dataset in DATASETS:\n",
    "    for category in CATEGORIES:\n",
    "        os.makedirs(f\"{base_dir}/road_following_{dataset}/{category}\", exist_ok=True)\n",
    "\n",
    "print(f\"‚úÖ Data directories ready: {base_dir}\")\n",
    "\n",
    "# Step 3: Data collection class\n",
    "class DataCollector:\n",
    "    def __init__(self):\n",
    "        self.current_dataset = DATASETS[0]\n",
    "        self.current_category = CATEGORIES[0]\n",
    "        self.count = 0\n",
    "        self.collecting = False\n",
    "        \n",
    "    def get_save_path(self):\n",
    "        return f\"{base_dir}/road_following_{self.current_dataset}/{self.current_category}\"\n",
    "    \n",
    "    def get_count(self):\n",
    "        path = self.get_save_path()\n",
    "        if os.path.exists(path):\n",
    "            return len([f for f in os.listdir(path) if f.endswith('.jpg')])\n",
    "        return 0\n",
    "    \n",
    "    def save_image(self, image, x, y):\n",
    "        # Save image with click coordinates in filename\n",
    "        filename = f\"{x}_{y}_{str(uuid.uuid4())}.jpg\"\n",
    "        filepath = os.path.join(self.get_save_path(), filename)\n",
    "        \n",
    "        # Save the image\n",
    "        cv2.imwrite(filepath, image)\n",
    "        \n",
    "        # Update count\n",
    "        self.count = self.get_count()\n",
    "        print(f\"üíæ Saved: {filename} (Total: {self.count})\")\n",
    "        \n",
    "        return filepath\n",
    "\n",
    "# Initialize data collector\n",
    "collector = DataCollector()\n",
    "\n",
    "# Step 4: Create interactive widgets\n",
    "print(\"üéõÔ∏è Creating interactive interface...\")\n",
    "\n",
    "# Image display widget\n",
    "image_widget = ipywidgets.Image(\n",
    "    format='jpeg',\n",
    "    width=400,\n",
    "    height=400,\n",
    ")\n",
    "\n",
    "# Control widgets\n",
    "dataset_widget = ipywidgets.Dropdown(\n",
    "    options=DATASETS,\n",
    "    value=DATASETS[0],\n",
    "    description='Dataset:'\n",
    ")\n",
    "\n",
    "category_widget = ipywidgets.Dropdown(\n",
    "    options=CATEGORIES,\n",
    "    value=CATEGORIES[0],\n",
    "    description='Category:'\n",
    ")\n",
    "\n",
    "count_widget = ipywidgets.IntText(\n",
    "    value=collector.get_count(),\n",
    "    description='Count:',\n",
    "    disabled=True\n",
    ")\n",
    "\n",
    "# Click coordinates display\n",
    "click_info = ipywidgets.HTML(value=\"<b>Click on the image to collect data</b>\")\n",
    "\n",
    "# Collection status\n",
    "status_widget = ipywidgets.HTML(value=\"<b>Status: Ready</b>\")\n",
    "\n",
    "# Step 5: Update functions\n",
    "def update_dataset(change):\n",
    "    collector.current_dataset = change['new']\n",
    "    collector.count = collector.get_count()\n",
    "    count_widget.value = collector.count\n",
    "    status_widget.value = f\"<b>Status: Dataset {collector.current_dataset} selected</b>\"\n",
    "\n",
    "def update_category(change):\n",
    "    collector.current_category = change['new']\n",
    "    collector.count = collector.get_count()\n",
    "    count_widget.value = collector.count\n",
    "    status_widget.value = f\"<b>Status: Category {collector.current_category} selected</b>\"\n",
    "\n",
    "dataset_widget.observe(update_dataset, names='value')\n",
    "category_widget.observe(update_category, names='value')\n",
    "\n",
    "# Step 6: Camera feed and click handling\n",
    "def update_camera_feed():\n",
    "    \"\"\"Update camera feed continuously\"\"\"\n",
    "    while collector.collecting:\n",
    "        try:\n",
    "            img = camera.read()\n",
    "            if img is not None:\n",
    "                # Convert BGR to RGB for display\n",
    "                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                # Encode as JPEG\n",
    "                _, buffer = cv2.imencode('.jpg', img_rgb)\n",
    "                image_widget.value = buffer.tobytes()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Camera feed error: {e}\")\n",
    "            break\n",
    "        \n",
    "        time.sleep(0.1)  # 10 FPS display\n",
    "\n",
    "# Click handler for data collection\n",
    "def handle_click(x, y, width, height):\n",
    "    \"\"\"Handle click on image for data collection\"\"\"\n",
    "    try:\n",
    "        # Get current camera image\n",
    "        img = camera.read()\n",
    "        if img is not None:\n",
    "            # Scale click coordinates to image size\n",
    "            img_x = int((x / width) * camera.width)\n",
    "            img_y = int((y / height) * camera.height)\n",
    "            \n",
    "            # Save the image with click coordinates\n",
    "            filepath = collector.save_image(img, img_x, img_y)\n",
    "            \n",
    "            # Update displays\n",
    "            count_widget.value = collector.count\n",
    "            click_info.value = f\"<b>Last click: ({img_x}, {img_y}) - Saved!</b>\"\n",
    "            status_widget.value = f\"<b>Status: Saved image #{collector.count}</b>\"\n",
    "            \n",
    "            # Show preview with click point\n",
    "            preview_img = img.copy()\n",
    "            cv2.circle(preview_img, (img_x, img_y), 8, (0, 255, 0), 3)\n",
    "            preview_rgb = cv2.cvtColor(preview_img, cv2.COLOR_BGR2RGB)\n",
    "            _, buffer = cv2.imencode('.jpg', preview_rgb)\n",
    "            image_widget.value = buffer.tobytes()\n",
    "            \n",
    "        else:\n",
    "            status_widget.value = \"<b>Status: No camera image available</b>\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        status_widget.value = f\"<b>Status: Error - {e}</b>\"\n",
    "\n",
    "# Step 7: JavaScript for click handling\n",
    "click_handler_js = \"\"\"\n",
    "<script>\n",
    "function setupClickHandler() {\n",
    "    const images = document.querySelectorAll('.widget-image img');\n",
    "    images.forEach(img => {\n",
    "        img.style.cursor = 'crosshair';\n",
    "        img.onclick = function(event) {\n",
    "            const rect = img.getBoundingClientRect();\n",
    "            const x = event.clientX - rect.left;\n",
    "            const y = event.clientY - rect.top;\n",
    "            \n",
    "            // Send click to Python\n",
    "            const kernel = Jupyter.notebook.kernel;\n",
    "            kernel.execute(`handle_click(${x}, ${y}, ${rect.width}, ${rect.height})`);\n",
    "        };\n",
    "    });\n",
    "}\n",
    "\n",
    "// Setup click handler after a short delay\n",
    "setTimeout(setupClickHandler, 1000);\n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "# Step 8: Control buttons\n",
    "start_button = ipywidgets.Button(description=\"Start Collection\")\n",
    "stop_button = ipywidgets.Button(description=\"Stop Collection\")\n",
    "\n",
    "def start_collection(b):\n",
    "    collector.collecting = True\n",
    "    start_button.disabled = True\n",
    "    stop_button.disabled = False\n",
    "    status_widget.value = \"<b>Status: Collecting data - Click on image!</b>\"\n",
    "    \n",
    "    # Start camera feed thread\n",
    "    threading.Thread(target=update_camera_feed, daemon=True).start()\n",
    "\n",
    "def stop_collection(b):\n",
    "    collector.collecting = False\n",
    "    start_button.disabled = False\n",
    "    stop_button.disabled = True\n",
    "    status_widget.value = \"<b>Status: Collection stopped</b>\"\n",
    "\n",
    "start_button.on_click(start_collection)\n",
    "stop_button.on_click(stop_collection)\n",
    "\n",
    "# Step 9: Create layout\n",
    "controls = ipywidgets.VBox([\n",
    "    dataset_widget,\n",
    "    category_widget,\n",
    "    count_widget,\n",
    "    ipywidgets.HBox([start_button, stop_button]),\n",
    "    status_widget,\n",
    "    click_info\n",
    "])\n",
    "\n",
    "layout = ipywidgets.HBox([\n",
    "    image_widget,\n",
    "    controls\n",
    "])\n",
    "\n",
    "# Step 10: Display everything\n",
    "print(\"üéØ Data Collection Interface Ready!\")\n",
    "print(\"\\nInstructions:\")\n",
    "print(\"1. Click 'Start Collection'\")\n",
    "print(\"2. Click on the camera image where you want the car to go\")\n",
    "print(\"3. Images will be saved automatically with click coordinates\")\n",
    "print(\"4. Use different datasets (A, B) for different training sessions\")\n",
    "\n",
    "display(layout)\n",
    "\n",
    "# Add click handler JavaScript\n",
    "from IPython.display import HTML\n",
    "display(HTML(click_handler_js))\n",
    "\n",
    "print(\"\\n‚úÖ Setup complete! Start collecting data by clicking the button above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/checker/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/checker/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "616b34913a494fe1985c92951e5078ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='road_following_model.pth', description='model path'), HBox(children=(Button(descrip‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "device = torch.device('cuda')\n",
    "output_dim = 2 * len(dataset.categories)  # x, y coordinate for each category\n",
    "\n",
    "# ALEXNET\n",
    "# model = torchvision.models.alexnet(pretrained=True)\n",
    "# model.classifier[-1] = torch.nn.Linear(4096, output_dim)\n",
    "\n",
    "# SQUEEZENET \n",
    "# model = torchvision.models.squeezenet1_1(pretrained=True)\n",
    "# model.classifier[1] = torch.nn.Conv2d(512, output_dim, kernel_size=1)\n",
    "# model.num_classes = len(dataset.categories)\n",
    "\n",
    "# RESNET 18\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Linear(512, output_dim)\n",
    "\n",
    "# RESNET 34\n",
    "# model = torchvision.models.resnet34(pretrained=True)\n",
    "# model.fc = torch.nn.Linear(512, output_dim)\n",
    "\n",
    "# DENSENET 121\n",
    "# model = torchvision.models.densenet121(pretrained=True)\n",
    "# model.classifier = torch.nn.Linear(model.num_features, output_dim)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "model_save_button = ipywidgets.Button(description='save model')\n",
    "model_load_button = ipywidgets.Button(description='load model')\n",
    "model_path_widget = ipywidgets.Text(description='model path', value='road_following_model.pth')\n",
    "\n",
    "def load_model(c):\n",
    "    model.load_state_dict(torch.load(model_path_widget.value))\n",
    "model_load_button.on_click(load_model)\n",
    "    \n",
    "def save_model(c):\n",
    "    torch.save(model.state_dict(), model_path_widget.value)\n",
    "model_save_button.on_click(save_model)\n",
    "\n",
    "model_widget = ipywidgets.VBox([\n",
    "    model_path_widget,\n",
    "    ipywidgets.HBox([model_load_button, model_save_button])\n",
    "])\n",
    "\n",
    "\n",
    "display(model_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Live Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42f1c028f5ef4f118bcff33c3866799a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Image(value=b'', format='jpeg', height='720', width='1280'), ToggleButtons(description='state',‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "from utils import preprocess\n",
    "import torch.nn.functional as F\n",
    "\n",
    "state_widget = ipywidgets.ToggleButtons(options=['stop', 'live'], description='state', value='stop')\n",
    "prediction_widget = ipywidgets.Image(format='jpeg', width=camera.width, height=camera.height)\n",
    "\n",
    "def live(state_widget, model, camera, prediction_widget):\n",
    "    global dataset\n",
    "    while state_widget.value == 'live':\n",
    "        image = camera.value\n",
    "        preprocessed = preprocess(image)\n",
    "        output = model(preprocessed).detach().cpu().numpy().flatten()\n",
    "        category_index = dataset.categories.index(category_widget.value)\n",
    "        x = output[2 * category_index]\n",
    "        y = output[2 * category_index + 1]\n",
    "        \n",
    "        x = int(camera.width * (x / 2.0 + 0.5))\n",
    "        y = int(camera.height * (y / 2.0 + 0.5))\n",
    "        \n",
    "        prediction = image.copy()\n",
    "        prediction = cv2.circle(prediction, (x, y), 8, (255, 0, 0), 3)\n",
    "        prediction_widget.value = bgr8_to_jpeg(prediction)\n",
    "            \n",
    "def start_live(change):\n",
    "    if change['new'] == 'live':\n",
    "        execute_thread = threading.Thread(target=live, args=(state_widget, model, camera, prediction_widget))\n",
    "        execute_thread.start()\n",
    "\n",
    "state_widget.observe(start_live, names='value')\n",
    "\n",
    "live_execution_widget = ipywidgets.VBox([\n",
    "    prediction_widget,\n",
    "    state_widget\n",
    "])\n",
    "\n",
    "display(live_execution_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73e53bed9bd4ead862d918324dc37f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntText(value=1, description='epochs'), FloatProgress(value=0.0, description='progress', max=1.‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
    "\n",
    "epochs_widget = ipywidgets.IntText(description='epochs', value=1)\n",
    "eval_button = ipywidgets.Button(description='evaluate')\n",
    "train_button = ipywidgets.Button(description='train')\n",
    "loss_widget = ipywidgets.FloatText(description='loss')\n",
    "progress_widget = ipywidgets.FloatProgress(min=0.0, max=1.0, description='progress')\n",
    "\n",
    "def train_eval(is_training):\n",
    "    global BATCH_SIZE, LEARNING_RATE, MOMENTUM, model, dataset, optimizer, eval_button, train_button, accuracy_widget, loss_widget, progress_widget, state_widget\n",
    "    \n",
    "    try:\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        state_widget.value = 'stop'\n",
    "        train_button.disabled = True\n",
    "        eval_button.disabled = True\n",
    "        time.sleep(1)\n",
    "\n",
    "        if is_training:\n",
    "            model = model.train()\n",
    "        else:\n",
    "            model = model.eval()\n",
    "\n",
    "        while epochs_widget.value > 0:\n",
    "            i = 0\n",
    "            sum_loss = 0.0\n",
    "            error_count = 0.0\n",
    "            for images, category_idx, xy in iter(train_loader):\n",
    "                # send data to device\n",
    "                images = images.to(device)\n",
    "                xy = xy.to(device)\n",
    "\n",
    "                if is_training:\n",
    "                    # zero gradients of parameters\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                # execute model to get outputs\n",
    "                outputs = model(images)\n",
    "\n",
    "                # compute MSE loss over x, y coordinates for associated categories\n",
    "                loss = 0.0\n",
    "                for batch_idx, cat_idx in enumerate(list(category_idx.flatten())):\n",
    "                    loss += torch.mean((outputs[batch_idx][2 * cat_idx:2 * cat_idx+2] - xy[batch_idx])**2)\n",
    "                loss /= len(category_idx)\n",
    "\n",
    "                if is_training:\n",
    "                    # run backpropogation to accumulate gradients\n",
    "                    loss.backward()\n",
    "\n",
    "                    # step optimizer to adjust parameters\n",
    "                    optimizer.step()\n",
    "\n",
    "                # increment progress\n",
    "                count = len(category_idx.flatten())\n",
    "                i += count\n",
    "                sum_loss += float(loss)\n",
    "                progress_widget.value = i / len(dataset)\n",
    "                loss_widget.value = sum_loss / i\n",
    "                \n",
    "            if is_training:\n",
    "                epochs_widget.value = epochs_widget.value - 1\n",
    "            else:\n",
    "                break\n",
    "    except e:\n",
    "        pass\n",
    "    model = model.eval()\n",
    "\n",
    "    train_button.disabled = False\n",
    "    eval_button.disabled = False\n",
    "    state_widget.value = 'live'\n",
    "    \n",
    "train_button.on_click(lambda c: train_eval(is_training=True))\n",
    "eval_button.on_click(lambda c: train_eval(is_training=False))\n",
    "    \n",
    "train_eval_widget = ipywidgets.VBox([\n",
    "    epochs_widget,\n",
    "    progress_widget,\n",
    "    loss_widget,\n",
    "    ipywidgets.HBox([train_button, eval_button])\n",
    "])\n",
    "\n",
    "display(train_eval_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All together!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following widget can be used to label a multi-class x, y dataset.  It supports labeling only one instance of each class per image (ie: only one dog), but multiple classes (ie: dog, cat, horse) per image are possible.\n",
    "\n",
    "Click the image on the top left to save an image of ``category`` to ``dataset`` at the clicked location.\n",
    "\n",
    "| Widget | Description |\n",
    "|--------|-------------|\n",
    "| dataset | Selects the active dataset |\n",
    "| category | Selects the active category |\n",
    "| epochs | Sets the number of epochs to train for |\n",
    "| train | Trains on the active dataset for the number of epochs specified |\n",
    "| evaluate | Evaluates the accuracy on the active dataset over one epoch |\n",
    "| model path | Sets the active model path |\n",
    "| load | Loads a model from the active model path |\n",
    "| save | Saves a model to the active model path |\n",
    "| stop | Disables the live demo |\n",
    "| live | Enables the live demo |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÅ AUTONOMOUS DRIVING - Complete CPU\n",
      "========================================\n",
      "\n",
      "üöÄ COMPLETE CPU AUTONOMOUS DRIVING READY!\n",
      "Functions available:\n",
      "  start_autonomous_driving() - Start complete CPU racing\n",
      "\n",
      "‚öôÔ∏è COMPLETE CPU SETTINGS:\n",
      "   Device: CPU only\n",
      "   Preprocessing: CPU only\n",
      "   Model: CPU only\n",
      "   Base throttle: 0.2\n",
      "\n",
      "üèÅ Ready for complete CPU autonomous driving!\n"
     ]
    }
   ],
   "source": [
    "# üèÅ AUTONOMOUS DRIVING - Complete CPU Version\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import smbus\n",
    "import threading\n",
    "import PIL.Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "print(\"üèÅ AUTONOMOUS DRIVING - Complete CPU\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Force CPU everywhere\n",
    "torch.cuda.is_available = lambda: False\n",
    "device = torch.device('cpu')\n",
    "\n",
    "class AutonomousRacecar:\n",
    "    def __init__(self):\n",
    "        self.bus = smbus.SMBus(7)\n",
    "        self.address = 0x40\n",
    "        \n",
    "        # Servo channels\n",
    "        self.steering_channel = 0\n",
    "        self.throttle_channel = 1\n",
    "        \n",
    "        # Current positions\n",
    "        self.current_steering = 1500\n",
    "        self.current_throttle = 1500\n",
    "        \n",
    "        # Position limits\n",
    "        self.min_pulse = 1000\n",
    "        self.max_pulse = 2000\n",
    "        self.center_pulse = 1500\n",
    "        \n",
    "        # FULL throttle range for speed\n",
    "        self.max_forward = 1200\n",
    "        self.throttle_neutral = 1500\n",
    "        \n",
    "        print(f\"üöó Using throttle range: {self.max_forward}-{self.throttle_neutral}Œºs\")\n",
    "        \n",
    "        # Calibrated steering offset\n",
    "        self.steering_offset_pulse = int(0.17 * 500)  # 85Œºs offset\n",
    "        \n",
    "        # Signal refresh\n",
    "        self.keep_refreshing = False\n",
    "        self.refresh_thread = None\n",
    "        \n",
    "        # Initialize\n",
    "        self.initialize_pca9685()\n",
    "        self.start_signal_refresh()\n",
    "        \n",
    "        print(\"‚úÖ Autonomous Racecar ready!\")\n",
    "    \n",
    "    def initialize_pca9685(self):\n",
    "        try:\n",
    "            self.bus.write_byte_data(self.address, 0x00, 0x10)\n",
    "            time.sleep(0.005)\n",
    "            prescale = int(25000000 / (4096 * 50) - 1)\n",
    "            self.bus.write_byte_data(self.address, 0xFE, prescale)\n",
    "            self.bus.write_byte_data(self.address, 0x00, 0x20)\n",
    "            time.sleep(0.005)\n",
    "            self.bus.write_byte_data(self.address, 0x01, 0x04)\n",
    "            self.bus.write_byte_data(self.address, 0xFA, 0x00)\n",
    "            self.bus.write_byte_data(self.address, 0xFB, 0x00)\n",
    "            self.bus.write_byte_data(self.address, 0xFC, 0x00)\n",
    "            self.bus.write_byte_data(self.address, 0xFD, 0x00)\n",
    "            \n",
    "            self.set_servo_position(self.steering_channel, self.center_pulse)\n",
    "            self.set_servo_position(self.throttle_channel, self.throttle_neutral)\n",
    "            print(\"‚úÖ PCA9685 initialized\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Init failed: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def set_servo_position(self, channel, pulse_us):\n",
    "        pulse_us = max(self.min_pulse, min(self.max_pulse, pulse_us))\n",
    "        pwm_val = int((pulse_us * 4096) / 20000)\n",
    "        base_reg = 0x06 + 4 * channel\n",
    "        \n",
    "        try:\n",
    "            self.bus.write_byte_data(self.address, base_reg, 0)\n",
    "            self.bus.write_byte_data(self.address, base_reg + 1, 0)\n",
    "            self.bus.write_byte_data(self.address, base_reg + 2, pwm_val & 0xFF)\n",
    "            self.bus.write_byte_data(self.address, base_reg + 3, (pwm_val >> 8) & 0xFF)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Servo error: {e}\")\n",
    "    \n",
    "    def start_signal_refresh(self):\n",
    "        self.keep_refreshing = True\n",
    "        def refresh_loop():\n",
    "            while self.keep_refreshing:\n",
    "                self.set_servo_position(self.throttle_channel, self.current_throttle)\n",
    "                self.set_servo_position(self.steering_channel, self.current_steering)\n",
    "                time.sleep(0.02)\n",
    "        \n",
    "        self.refresh_thread = threading.Thread(target=refresh_loop, daemon=True)\n",
    "        self.refresh_thread.start()\n",
    "    \n",
    "    def stop_signal_refresh(self):\n",
    "        self.keep_refreshing = False\n",
    "    \n",
    "    def set_steering(self, value):\n",
    "        steering_pulse = self.center_pulse + int(value * 500) + self.steering_offset_pulse\n",
    "        steering_pulse = max(self.min_pulse, min(self.max_pulse, steering_pulse))\n",
    "        self.current_steering = steering_pulse\n",
    "        self.set_servo_position(self.steering_channel, steering_pulse)\n",
    "    \n",
    "    def set_throttle(self, value):\n",
    "        if value > 0:\n",
    "            new_throttle = self.throttle_neutral - int(value * (self.throttle_neutral - self.max_forward))\n",
    "            new_throttle = max(self.max_forward, new_throttle)\n",
    "        else:\n",
    "            new_throttle = self.throttle_neutral\n",
    "        \n",
    "        self.current_throttle = new_throttle\n",
    "        self.set_servo_position(self.throttle_channel, new_throttle)\n",
    "    \n",
    "    def stop(self):\n",
    "        self.current_steering = self.center_pulse\n",
    "        self.current_throttle = self.throttle_neutral\n",
    "        self.set_servo_position(self.steering_channel, self.current_steering)\n",
    "        self.set_servo_position(self.throttle_channel, self.current_throttle)\n",
    "        print(\"üõë STOPPED\")\n",
    "    \n",
    "    def cleanup(self):\n",
    "        self.stop_signal_refresh()\n",
    "        self.stop()\n",
    "\n",
    "def initialize_camera():\n",
    "    print(\"üé¨ Initializing camera...\")\n",
    "    try:\n",
    "        from jetcam.csi_camera import CSICamera\n",
    "        camera = CSICamera(width=224, height=224, capture_fps=21)\n",
    "        camera.running = True\n",
    "        time.sleep(3)\n",
    "        \n",
    "        test_img = camera.value\n",
    "        if test_img is not None:\n",
    "            print(f\"‚úÖ Camera working! Shape: {test_img.shape}\")\n",
    "            return camera\n",
    "        else:\n",
    "            print(\"‚ùå Camera not capturing\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Camera failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_camera_image(camera):\n",
    "    if camera is None:\n",
    "        return None\n",
    "    try:\n",
    "        img = camera.value\n",
    "        if img is not None and img.shape[:2] != (224, 224):\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def cpu_preprocess(image):\n",
    "    \"\"\"CPU-only preprocessing - replaces utils.preprocess()\"\"\"\n",
    "    # Convert to PIL Image\n",
    "    image_pil = PIL.Image.fromarray(image)\n",
    "    \n",
    "    # Create CPU-only transform\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Apply transform and ensure CPU\n",
    "    tensor = transform(image_pil)\n",
    "    tensor = tensor.unsqueeze(0)  # Add batch dimension\n",
    "    \n",
    "    # Force CPU\n",
    "    tensor = tensor.to(device)\n",
    "    \n",
    "    return tensor\n",
    "\n",
    "def load_trained_model():\n",
    "    \"\"\"Load model with complete CPU forcing\"\"\"\n",
    "    print(\"ü§ñ Loading model on CPU...\")\n",
    "    CATEGORIES = ['apex']\n",
    "    \n",
    "    # Create model\n",
    "    model = torchvision.models.resnet18(weights=None)  # Use newer parameter\n",
    "    model.fc = torch.nn.Linear(512, 2 * len(CATEGORIES))\n",
    "    \n",
    "    # FORCE CPU\n",
    "    model = model.to(device)\n",
    "    \n",
    "    try:\n",
    "        # Load weights with CPU forcing\n",
    "        state_dict = torch.load('road_following_model_cpu.pth', \n",
    "                               map_location=device, weights_only=True)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.eval()\n",
    "        \n",
    "        # Double-check everything is on CPU\n",
    "        for name, param in model.named_parameters():\n",
    "            param.data = param.data.to(device)\n",
    "        \n",
    "        print(\"‚úÖ Model loaded completely on CPU!\")\n",
    "        print(f\"‚úÖ Model device: {next(model.parameters()).device}\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Model failed: {e}\")\n",
    "        return None\n",
    "\n",
    "class DrivingParams:\n",
    "    THROTTLE = 0.2\n",
    "    STEERING_GAIN = 1.5\n",
    "    STEERING_BIAS = 0.0\n",
    "    MAX_STEERING = 1.0\n",
    "    MIN_STEERING = -1.0\n",
    "    UPDATE_RATE = 0.05\n",
    "\n",
    "def start_autonomous_driving():\n",
    "    \"\"\"Complete CPU autonomous driving\"\"\"\n",
    "    print(\"\\nüèÅ STARTING COMPLETE CPU AUTONOMOUS DRIVING!\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    model = load_trained_model()\n",
    "    if model is None:\n",
    "        return\n",
    "    \n",
    "    print(\"‚ö†Ô∏è  SAFETY REMINDERS:\")\n",
    "    print(\"   ‚Ä¢ Keep manual override ready!\")\n",
    "    print(\"   ‚Ä¢ Press Ctrl+C to stop\")\n",
    "    print(f\"   ‚Ä¢ Complete CPU processing\")\n",
    "    print(f\"   ‚Ä¢ Base throttle: {DrivingParams.THROTTLE}\")\n",
    "    \n",
    "    print(\"\\n‚è±Ô∏è  Starting in 5 seconds...\")\n",
    "    for i in range(5, 0, -1):\n",
    "        print(f\"   {i}...\")\n",
    "        time.sleep(1)\n",
    "    \n",
    "    print(\"üöÄ GO!\")\n",
    "    \n",
    "    camera = initialize_camera()\n",
    "    car = AutonomousRacecar()\n",
    "    \n",
    "    if camera is None:\n",
    "        car.cleanup()\n",
    "        return\n",
    "    \n",
    "    car.set_throttle(DrivingParams.THROTTLE)\n",
    "    expected_pulse = 1500 - int(DrivingParams.THROTTLE * 300)\n",
    "    print(f\"üöó Throttle set to {DrivingParams.THROTTLE} (~{expected_pulse}Œºs)\")\n",
    "    \n",
    "    frame_count = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        print(\"üéØ Complete CPU autonomous driving active!\")\n",
    "        \n",
    "        while True:\n",
    "            # Get image\n",
    "            image = get_camera_image(camera)\n",
    "            if image is None:\n",
    "                continue\n",
    "            \n",
    "            # CPU-only preprocessing (no utils.preprocess)\n",
    "            processed_image = cpu_preprocess(image)\n",
    "            \n",
    "            # CPU-only inference\n",
    "            with torch.no_grad():\n",
    "                output = model(processed_image)\n",
    "                steering_prediction = float(output[0][0].cpu())\n",
    "            \n",
    "            # Apply steering\n",
    "            ai_steering_command = (steering_prediction * DrivingParams.STEERING_GAIN + \n",
    "                                 DrivingParams.STEERING_BIAS)\n",
    "            ai_steering_command = max(DrivingParams.MIN_STEERING, \n",
    "                                    min(DrivingParams.MAX_STEERING, ai_steering_command))\n",
    "            \n",
    "            car.set_steering(ai_steering_command)\n",
    "            \n",
    "            frame_count += 1\n",
    "            if frame_count % 50 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                fps = frame_count / elapsed\n",
    "                print(f\"üìä Frame {frame_count} | FPS: {fps:.1f} | \"\n",
    "                      f\"Steering: {ai_steering_command:+.3f}\")\n",
    "            \n",
    "            time.sleep(DrivingParams.UPDATE_RATE)\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nüõë STOPPING AUTONOMOUS DRIVING\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        car.cleanup()\n",
    "        if camera:\n",
    "            camera.running = False\n",
    "        print(\"üõë Complete CPU autonomous driving stopped safely\")\n",
    "\n",
    "print(\"\\nüöÄ COMPLETE CPU AUTONOMOUS DRIVING READY!\")\n",
    "print(\"Functions available:\")\n",
    "print(\"  start_autonomous_driving() - Start complete CPU racing\")\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è COMPLETE CPU SETTINGS:\")\n",
    "print(f\"   Device: CPU only\")\n",
    "print(f\"   Preprocessing: CPU only\")\n",
    "print(f\"   Model: CPU only\")\n",
    "print(f\"   Base throttle: {DrivingParams.THROTTLE}\")\n",
    "\n",
    "print(f\"\\nüèÅ Ready for complete CPU autonomous driving!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_throttle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_throttle\u001b[49m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_throttle' is not defined"
     ]
    }
   ],
   "source": [
    "test_throttle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé¨ Initializing camera...\n",
      "GST_ARGUS: Creating output stream\n",
      "CONSUMER: Waiting until producer is connected...\n",
      "GST_ARGUS: Available Sensor modes :\n",
      "GST_ARGUS: 3280 x 2464 FR = 21.000000 fps Duration = 47619048 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 3280 x 1848 FR = 28.000001 fps Duration = 35714284 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 1920 x 1080 FR = 29.999999 fps Duration = 33333334 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 1640 x 1232 FR = 29.999999 fps Duration = 33333334 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 1280 x 720 FR = 59.999999 fps Duration = 16666667 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: Running with following settings:\n",
      "   Camera index = 0 \n",
      "   Camera mode  = 4 \n",
      "   Output Stream W = 1280 H = 720 \n",
      "   seconds to Run    = 0 \n",
      "   Frame Rate = 59.999999 \n",
      "GST_ARGUS: Setup Complete, Starting captures for 0 seconds\n",
      "GST_ARGUS: Starting repeat capture requests.\n",
      "CONSUMER: Producer has connected; continuing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@286.863] global cap_gstreamer.cpp:1728 open OpenCV | GStreamer warning: Cannot query video position: status=0, value=-1, duration=-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Camera working! Shape: (224, 224, 3)\n",
      "üì∑ Testing camera capture...\n",
      "‚úÖ Capture 1: (224, 224, 3)\n",
      "‚úÖ Capture 2: (224, 224, 3)\n",
      "‚úÖ Capture 3: (224, 224, 3)\n",
      "‚úÖ Capture 4: (224, 224, 3)\n",
      "‚úÖ Capture 5: (224, 224, 3)\n",
      "‚úÖ Camera test complete!\n"
     ]
    }
   ],
   "source": [
    "# Quick camera test\n",
    "camera = initialize_camera()\n",
    "\n",
    "if camera:\n",
    "    print(\"üì∑ Testing camera capture...\")\n",
    "    for i in range(5):\n",
    "        img = get_camera_image(camera)\n",
    "        if img is not None:\n",
    "            print(f\"‚úÖ Capture {i+1}: {img.shape}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Capture {i+1}: Failed\")\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    camera.running = False\n",
    "    print(\"‚úÖ Camera test complete!\")\n",
    "else:\n",
    "    print(\"‚ùå Camera failed to initialize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÅ STARTING COMPLETE CPU AUTONOMOUS DRIVING!\n",
      "========================================\n",
      "ü§ñ Loading model on CPU...\n",
      "‚úÖ Model loaded completely on CPU!\n",
      "‚úÖ Model device: cpu\n",
      "‚ö†Ô∏è  SAFETY REMINDERS:\n",
      "   ‚Ä¢ Keep manual override ready!\n",
      "   ‚Ä¢ Press Ctrl+C to stop\n",
      "   ‚Ä¢ Complete CPU processing\n",
      "   ‚Ä¢ Base throttle: 0.4\n",
      "\n",
      "‚è±Ô∏è  Starting in 5 seconds...\n",
      "   5...\n",
      "   4...\n",
      "   3...\n",
      "   2...\n",
      "   1...\n",
      "üöÄ GO!\n",
      "üé¨ Initializing camera...\n",
      "GST_ARGUS: Creating output stream\n",
      "CONSUMER: Waiting until producer is connected...\n",
      "GST_ARGUS: Available Sensor modes :\n",
      "GST_ARGUS: 3280 x 2464 FR = 21.000000 fps Duration = 47619048 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 3280 x 1848 FR = 28.000001 fps Duration = 35714284 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 1920 x 1080 FR = 29.999999 fps Duration = 33333334 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 1640 x 1232 FR = 29.999999 fps Duration = 33333334 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 1280 x 720 FR = 59.999999 fps Duration = 16666667 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: Running with following settings:\n",
      "   Camera index = 0 \n",
      "   Camera mode  = 4 \n",
      "   Output Stream W = 1280 H = 720 \n",
      "   seconds to Run    = 0 \n",
      "   Frame Rate = 59.999999 \n",
      "GST_ARGUS: Setup Complete, Starting captures for 0 seconds\n",
      "GST_ARGUS: Starting repeat capture requests.\n",
      "CONSUMER: Producer has connected; continuing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@37.578] global cap_gstreamer.cpp:1728 open OpenCV | GStreamer warning: Cannot query video position: status=0, value=-1, duration=-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Camera working! Shape: (224, 224, 3)\n",
      "üöó Using throttle range: 1200-1500Œºs\n",
      "‚úÖ PCA9685 initialized\n",
      "‚úÖ Autonomous Racecar ready!\n",
      "üöó Throttle set to 0.4 (~1380Œºs)\n",
      "üéØ Complete CPU autonomous driving active!\n",
      "üìä Frame 50 | FPS: 5.4 | Steering: +0.002\n",
      "üìä Frame 100 | FPS: 5.5 | Steering: +0.008\n",
      "üìä Frame 150 | FPS: 5.5 | Steering: +0.007\n",
      "üìä Frame 200 | FPS: 5.5 | Steering: +0.001\n",
      "üìä Frame 250 | FPS: 5.5 | Steering: +0.002\n",
      "üìä Frame 300 | FPS: 5.5 | Steering: +0.002\n",
      "üìä Frame 350 | FPS: 5.5 | Steering: +0.002\n",
      "üìä Frame 400 | FPS: 5.6 | Steering: +0.002\n",
      "üìä Frame 450 | FPS: 5.6 | Steering: +0.002\n",
      "üìä Frame 500 | FPS: 5.6 | Steering: +0.002\n",
      "üìä Frame 550 | FPS: 5.6 | Steering: +0.002\n",
      "üìä Frame 600 | FPS: 5.6 | Steering: +0.002\n",
      "üìä Frame 650 | FPS: 5.6 | Steering: +0.002\n",
      "üìä Frame 700 | FPS: 5.6 | Steering: +0.002\n",
      "üìä Frame 750 | FPS: 5.6 | Steering: +0.002\n",
      "üìä Frame 800 | FPS: 5.6 | Steering: +0.002\n",
      "üìä Frame 850 | FPS: 5.6 | Steering: +0.002\n",
      "üìä Frame 900 | FPS: 5.6 | Steering: +0.002\n",
      "üìä Frame 950 | FPS: 5.6 | Steering: +0.002\n",
      "üìä Frame 1000 | FPS: 5.6 | Steering: +0.002\n",
      "üìä Frame 1050 | FPS: 5.6 | Steering: +0.002\n",
      "üìä Frame 1100 | FPS: 5.6 | Steering: +0.002\n",
      "üìä Frame 1150 | FPS: 5.6 | Steering: +0.002\n",
      "üìä Frame 1200 | FPS: 5.6 | Steering: +0.002\n",
      "üìä Frame 1250 | FPS: 5.6 | Steering: +0.002\n",
      "üìä Frame 1300 | FPS: 5.6 | Steering: +0.002\n",
      "üìä Frame 1350 | FPS: 5.6 | Steering: +0.002\n",
      "üìä Frame 1400 | FPS: 5.6 | Steering: +0.002\n",
      "üìä Frame 1450 | FPS: 5.6 | Steering: +0.002\n",
      "üìä Frame 1500 | FPS: 5.6 | Steering: +0.001\n",
      "üìä Frame 1550 | FPS: 5.6 | Steering: +0.002\n",
      "üìä Frame 1600 | FPS: 5.6 | Steering: +0.002\n",
      "üìä Frame 1650 | FPS: 5.6 | Steering: +0.002\n",
      "üìä Frame 1700 | FPS: 5.6 | Steering: +0.002\n",
      "üìä Frame 1750 | FPS: 5.6 | Steering: +0.002\n",
      "üìä Frame 1800 | FPS: 5.6 | Steering: +0.002\n",
      "üìä Frame 1850 | FPS: 5.6 | Steering: +0.003\n",
      "üìä Frame 1900 | FPS: 5.6 | Steering: +0.002\n",
      "üìä Frame 1950 | FPS: 5.6 | Steering: +0.002\n",
      "üìä Frame 2000 | FPS: 5.6 | Steering: +0.002\n",
      "üìä Frame 2050 | FPS: 5.6 | Steering: +0.002\n",
      "üìä Frame 2100 | FPS: 5.6 | Steering: -0.002\n"
     ]
    }
   ],
   "source": [
    "start_autonomous_driving()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Looking for your model file...\n",
      "üìÅ Current directory .pth files: ['road_following_model_cpu.pth']\n",
      "\n",
      "üìç Checking common locations:\n",
      "‚úÖ FOUND: ./road_following_model_cpu.pth\n",
      "   Size: 44,789,468 bytes\n",
      "‚ùå Not found: ./notebooks/road_following_model_cpu.pth\n",
      "‚ùå Not found: /home/checker/road_following_model_cpu.pth\n",
      "‚ùå Not found: /home/checker/Autonomous-Racecar/road_following_model_cpu.pth\n",
      "‚ùå Not found: /home/checker/notebooks/road_following_model_cpu.pth\n",
      "\n",
      "üîç Searching for ALL .pth files...\n",
      "üìÑ Found: /home/checker/jetracer/notebooks/road_following_model_cpu.pth (44,789,468 bytes)\n",
      "üìÑ Found: /home/checker/Autonomous-Racecar/notebooks/road_following_model_cpu.pth (44,789,468 bytes)\n"
     ]
    }
   ],
   "source": [
    "# Find your model file\n",
    "import os\n",
    "\n",
    "print(\"üîç Looking for your model file...\")\n",
    "\n",
    "# Check current directory\n",
    "current_files = [f for f in os.listdir('.') if f.endswith('.pth')]\n",
    "print(f\"üìÅ Current directory .pth files: {current_files}\")\n",
    "\n",
    "# Check common locations\n",
    "common_paths = [\n",
    "    './road_following_model_cpu.pth',\n",
    "    './notebooks/road_following_model_cpu.pth', \n",
    "    '/home/checker/road_following_model_cpu.pth',\n",
    "    '/home/checker/Autonomous-Racecar/road_following_model_cpu.pth',\n",
    "    '/home/checker/notebooks/road_following_model_cpu.pth'\n",
    "]\n",
    "\n",
    "print(\"\\nüìç Checking common locations:\")\n",
    "for path in common_paths:\n",
    "    if os.path.exists(path):\n",
    "        print(f\"‚úÖ FOUND: {path}\")\n",
    "        print(f\"   Size: {os.path.getsize(path):,} bytes\")\n",
    "    else:\n",
    "        print(f\"‚ùå Not found: {path}\")\n",
    "\n",
    "# Search for any .pth files\n",
    "print(\"\\nüîç Searching for ALL .pth files...\")\n",
    "for root, dirs, files in os.walk('/home/checker'):\n",
    "    for file in files:\n",
    "        if file.endswith('.pth') and 'road_following' in file:\n",
    "            full_path = os.path.join(root, file)\n",
    "            size = os.path.getsize(full_path)\n",
    "            print(f\"üìÑ Found: {full_path} ({size:,} bytes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß THROTTLE TEST - Correct Range 1400-1500\n",
      "========================================\n",
      "üöó Using CORRECT throttle range:\n",
      "   Forward: 1400Œºs\n",
      "   Neutral: 1500Œºs\n",
      "   Range: 1400-1500Œºs\n",
      "Set throttle to 1500Œºs\n",
      "‚úÖ PCA9685 initialized\n",
      "‚úÖ Correct throttle test ready\n",
      "\n",
      "üöó TESTING CORRECT RANGE: 1400-1500\n",
      "1. Neutral (1500Œºs)...\n",
      "Set throttle to 1500Œºs\n",
      "2. Forward speed (1480Œºs)...\n",
      "Set throttle to 1480Œºs\n",
      "   Back to neutral...\n",
      "Set throttle to 1500Œºs\n",
      "2. Forward speed (1460Œºs)...\n",
      "Set throttle to 1460Œºs\n",
      "   Back to neutral...\n",
      "Set throttle to 1500Œºs\n",
      "2. Forward speed (1440Œºs)...\n",
      "Set throttle to 1440Œºs\n",
      "   Back to neutral...\n",
      "Set throttle to 1500Œºs\n",
      "2. Forward speed (1420Œºs)...\n",
      "Set throttle to 1420Œºs\n",
      "   Back to neutral...\n",
      "Set throttle to 1500Œºs\n",
      "2. Forward speed (1400Œºs)...\n",
      "Set throttle to 1400Œºs\n",
      "   Back to neutral...\n",
      "Set throttle to 1500Œºs\n",
      "‚úÖ Correct range test complete!\n"
     ]
    }
   ],
   "source": [
    "# üîß CORRECT THROTTLE TEST - Using 1400-1500 Range\n",
    "import smbus\n",
    "import time\n",
    "\n",
    "print(\"üîß THROTTLE TEST - Correct Range 1400-1500\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "class CorrectThrottleTest:\n",
    "    def __init__(self):\n",
    "        self.bus = smbus.SMBus(7)\n",
    "        self.address = 0x40\n",
    "        self.throttle_channel = 1\n",
    "        \n",
    "        # CORRECT throttle range\n",
    "        self.center_pulse = 1500\n",
    "        self.max_forward = 1400   # Forward = lower values\n",
    "        self.max_reverse = 1500   # Only goes down to center, no reverse?\n",
    "        \n",
    "        print(f\"üöó Using CORRECT throttle range:\")\n",
    "        print(f\"   Forward: {self.max_forward}Œºs\")\n",
    "        print(f\"   Neutral: {self.center_pulse}Œºs\")\n",
    "        print(f\"   Range: {self.max_forward}-{self.center_pulse}Œºs\")\n",
    "        \n",
    "        self.initialize_pca9685()\n",
    "        print(\"‚úÖ Correct throttle test ready\")\n",
    "    \n",
    "    def initialize_pca9685(self):\n",
    "        try:\n",
    "            self.bus.write_byte_data(self.address, 0x00, 0x10)\n",
    "            time.sleep(0.005)\n",
    "            prescale = int(25000000 / (4096 * 50) - 1)\n",
    "            self.bus.write_byte_data(self.address, 0xFE, prescale)\n",
    "            self.bus.write_byte_data(self.address, 0x00, 0x20)\n",
    "            time.sleep(0.005)\n",
    "            self.bus.write_byte_data(self.address, 0x01, 0x04)\n",
    "            self.bus.write_byte_data(self.address, 0xFA, 0x00)\n",
    "            self.bus.write_byte_data(self.address, 0xFB, 0x00)\n",
    "            self.bus.write_byte_data(self.address, 0xFC, 0x00)\n",
    "            self.bus.write_byte_data(self.address, 0xFD, 0x00)\n",
    "            self.set_servo_position(self.throttle_channel, self.center_pulse)\n",
    "            print(\"‚úÖ PCA9685 initialized\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Init failed: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def set_servo_position(self, channel, pulse_us):\n",
    "        pulse_us = max(1000, min(2000, pulse_us))\n",
    "        pwm_val = int((pulse_us * 4096) / 20000)\n",
    "        base_reg = 0x06 + 4 * channel\n",
    "        \n",
    "        try:\n",
    "            self.bus.write_byte_data(self.address, base_reg, 0)\n",
    "            self.bus.write_byte_data(self.address, base_reg + 1, 0)\n",
    "            self.bus.write_byte_data(self.address, base_reg + 2, pwm_val & 0xFF)\n",
    "            self.bus.write_byte_data(self.address, base_reg + 3, (pwm_val >> 8) & 0xFF)\n",
    "            print(f\"Set throttle to {pulse_us}Œºs\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Servo error: {e}\")\n",
    "    \n",
    "    def test_correct_range(self):\n",
    "        \"\"\"Test the correct 1400-1500 range\"\"\"\n",
    "        print(\"\\nüöó TESTING CORRECT RANGE: 1400-1500\")\n",
    "        \n",
    "        # Start at neutral\n",
    "        print(\"1. Neutral (1500Œºs)...\")\n",
    "        self.set_servo_position(self.throttle_channel, 1500)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Test different forward speeds in the correct range\n",
    "        forward_speeds = [1480, 1460, 1440, 1420, 1400]\n",
    "        \n",
    "        for speed in forward_speeds:\n",
    "            print(f\"2. Forward speed ({speed}Œºs)...\")\n",
    "            self.set_servo_position(self.throttle_channel, speed)\n",
    "            time.sleep(3)\n",
    "            \n",
    "            print(\"   Back to neutral...\")\n",
    "            self.set_servo_position(self.throttle_channel, 1500)\n",
    "            time.sleep(1)\n",
    "        \n",
    "        print(\"‚úÖ Correct range test complete!\")\n",
    "\n",
    "# Test the correct range\n",
    "try:\n",
    "    throttle_test = CorrectThrottleTest()\n",
    "    throttle_test.test_correct_range()\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Test failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
