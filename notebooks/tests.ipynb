{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55ca3e9e-dc5e-4530-894f-472533677cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏁 JETRACER AUTONOMOUS DRIVING SYSTEM\n",
      "Using YOUR working camera code and calibrated car\n",
      "==================================================\n",
      "\n",
      "🎮 READY TO DRIVE WITH YOUR PROVEN METHODS!\n",
      "Functions available:\n",
      "  quick_camera_test() - Test your camera method\n",
      "  test_hardware() - Full hardware test\n",
      "  start_autonomous_driving() - GO RACING!\n",
      "\n",
      "⚙️ CURRENT SETTINGS:\n",
      "   Camera: CSICamera(224x224, 21fps) - YOUR WORKING METHOD\n",
      "   Hardware steering offset: 0.17 (your calibration)\n",
      "   AI throttle: 0.15 (start slow!)\n",
      "   AI steering gain: 0.75\n",
      "\n",
      "🏁 Your proven camera + calibrated hardware + 371-image model = READY!\n"
     ]
    }
   ],
   "source": [
    "# 🏁 AUTONOMOUS DRIVING - Using YOUR Working Camera Code\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "from utils import preprocess\n",
    "\n",
    "# Your exact working custom classes\n",
    "import traitlets\n",
    "import smbus\n",
    "\n",
    "class Racecar(traitlets.HasTraits):\n",
    "    steering = traitlets.Float()\n",
    "    throttle = traitlets.Float()\n",
    "    \n",
    "    @traitlets.validate('steering')\n",
    "    def _clip_steering(self, proposal):\n",
    "        return max(-1.0, min(1.0, proposal['value']))\n",
    "        \n",
    "    @traitlets.validate('throttle')\n",
    "    def _clip_throttle(self, proposal):\n",
    "        return max(-1.0, min(1.0, proposal['value']))\n",
    "\n",
    "class NvidiaRacecar(Racecar):\n",
    "    i2c_address = traitlets.Integer(default_value=0x40)v\n",
    "    steering_gain = traitlets.Float(default_value=-0.65)\n",
    "    steering_offset = traitlets.Float(default_value=0.17)  # YOUR CALIBRATED VALUE!\n",
    "    steering_channel = traitlets.Integer(default_value=0)\n",
    "    throttle_gain = traitlets.Float(default_value=0.8)\n",
    "    throttle_channel = traitlets.Integer(default_value=1)\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(NvidiaRacecar, self).__init__(*args, **kwargs)\n",
    "        self.bus = smbus.SMBus(7)\n",
    "        self.center_pulse = 1500\n",
    "        self._initialize_pca9685()\n",
    "        print(\"✅ NvidiaRacecar ready for autonomous driving!\")\n",
    "        print(f\"✅ Using calibrated steering offset: {self.steering_offset}\")\n",
    "    \n",
    "    def _initialize_pca9685(self):\n",
    "        try:\n",
    "            self.bus.write_byte_data(self.i2c_address, 0x00, 0x10)\n",
    "            time.sleep(0.005)\n",
    "            prescale = int(25000000 / (4096 * 50) - 1)\n",
    "            self.bus.write_byte_data(self.i2c_address, 0xFE, prescale)\n",
    "            self.bus.write_byte_data(self.i2c_address, 0x00, 0x20)\n",
    "            time.sleep(0.005)\n",
    "            self.bus.write_byte_data(self.i2c_address, 0x01, 0x04)\n",
    "            self._set_servo_pulse(0, self.center_pulse)\n",
    "            self._set_servo_pulse(1, self.center_pulse)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: {e}\")\n",
    "    \n",
    "    def _set_servo_pulse(self, channel, pulse_us):\n",
    "        pulse_us = max(1000, min(2000, pulse_us))\n",
    "        pwm_value = int((pulse_us * 4096) / 20000)\n",
    "        base_reg = 0x06 + 4 * channel\n",
    "        try:\n",
    "            self.bus.write_byte_data(self.i2c_address, base_reg, 0)\n",
    "            self.bus.write_byte_data(self.i2c_address, base_reg + 1, 0)\n",
    "            self.bus.write_byte_data(self.i2c_address, base_reg + 2, pwm_value & 0xFF)\n",
    "            self.bus.write_byte_data(self.i2c_address, base_reg + 3, (pwm_value >> 8) & 0xFF)\n",
    "        except Exception as e:\n",
    "            print(f\"PWM Error: {e}\")\n",
    "    \n",
    "    @traitlets.observe('steering')\n",
    "    def _on_steering(self, change):\n",
    "        scaled = change['new'] * self.steering_gain + self.steering_offset\n",
    "        pulse_us = self.center_pulse + (scaled * 500)\n",
    "        self._set_servo_pulse(self.steering_channel, pulse_us)\n",
    "    \n",
    "    @traitlets.observe('throttle')\n",
    "    def _on_throttle(self, change):\n",
    "        scaled = change['new'] * self.throttle_gain\n",
    "        if scaled > 0:\n",
    "            pulse_us = self.center_pulse - (scaled * 200)\n",
    "        elif scaled < 0:\n",
    "            pulse_us = self.center_pulse + (abs(scaled) * 200)\n",
    "        else:\n",
    "            pulse_us = self.center_pulse\n",
    "        self._set_servo_pulse(self.throttle_channel, pulse_us)\n",
    "\n",
    "print(\"🏁 JETRACER AUTONOMOUS DRIVING SYSTEM\")\n",
    "print(\"Using YOUR working camera code and calibrated car\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Initialize camera using YOUR working method\n",
    "def initialize_camera():\n",
    "    \"\"\"Initialize camera using your proven working method\"\"\"\n",
    "    print(\"🎬 Initializing camera using your working method...\")\n",
    "    try:\n",
    "        from jetcam.csi_camera import CSICamera\n",
    "        camera = CSICamera(width=224, height=224, capture_fps=21)\n",
    "        camera.running = True\n",
    "        print(\"✅ Camera creatved and started\")\n",
    "        \n",
    "        # Wait for camera to warm up (like in your code)\n",
    "        time.sleep(3)\n",
    "        \n",
    "        # Test camera using your method\n",
    "        test_img = camera.value\n",
    "        if test_img is not None:\n",
    "            print(f\"✅ Camera working! Shape: {test_img.shape}\")\n",
    "            return camera\n",
    "        else:\n",
    "            print(\"❌ Camera not capturing\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Camera initialization failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_camera_image(camera):\n",
    "    \"\"\"Get image from camera using YOUR working method\"\"\"\n",
    "    if camera is None:\n",
    "        return None\n",
    "    try:\n",
    "        img = camera.value  # Use .value for CSICamera when running (your method)\n",
    "        if img is not None and img.shape[:2] != (224, 224):\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting camera image: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_trained_model():\n",
    "    \"\"\"Load your CPU-trained model\"\"\"\n",
    "    print(\"🤖 Loading your 371-image trained model...\")\n",
    "    CATEGORIES = ['apex']\n",
    "    \n",
    "    model = torchvision.models.resnet18(pretrained=False)\n",
    "    model.fc = torch.nn.Linear(512, 2 * len(CATEGORIES))\n",
    "    model = model.float()\n",
    "    \n",
    "    try:\n",
    "        model.load_state_dict(torch.load('road_following_model_cpu.pth', \n",
    "                                       map_location='cpu', weights_only=True))\n",
    "        model.eval()\n",
    "        print(\"✅ Your trained model loaded successfully!\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to load model: {e}\")\n",
    "        return None\n",
    "\n",
    "class DrivingParams:\n",
    "    THROTTLE = 0.15          # Start VERY slow for safety\n",
    "    STEERING_GAIN = 0.75     # How responsive AI steering is  \n",
    "    STEERING_BIAS = 0.0      # Additional AI steering correction\n",
    "    MAX_STEERING = 1.0       # Safety limits\n",
    "    MIN_STEERING = -1.0\n",
    "    UPDATE_RATE = 0.05       # 20Hz\n",
    "\n",
    "def test_hardware():\n",
    "    \"\"\"Test your hardware using your working camera method\"\"\"\n",
    "    print(\"\\n🧪 TESTING HARDWARE\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    print(\"📷 Testing camera using your working method...\")\n",
    "    camera = initialize_camera()\n",
    "    \n",
    "    camera_ok = False\n",
    "    if camera is not None:\n",
    "        img = get_camera_image(camera)\n",
    "        if img is not None:\n",
    "            print(f\"✅ Camera working: {img.shape}\")\n",
    "            camera_ok = True\n",
    "        else:\n",
    "            print(\"❌ Camera not capturing images\")\n",
    "        \n",
    "        # Stop camera\n",
    "        camera.running = False\n",
    "    else:\n",
    "        print(\"❌ Camera failed to start\")\n",
    "    \n",
    "    print(\"🚗 Testing your calibrated car...\")\n",
    "    car_ok = False\n",
    "    try:\n",
    "        car = NvidiaRacecar()  # Uses your 0.17 offset\n",
    "        print(f\"  ✅ Car initialized with steering_offset = {car.steering_offset}\")\n",
    "        \n",
    "        print(\"  Testing calibrated steering...\")\n",
    "        car.steering = 0.0   # Should go straight with your calibration\n",
    "        time.sleep(1)\n",
    "        car.steering = 0.2   # Right turn\n",
    "        time.sleep(0.5)\n",
    "        car.steering = -0.2  # Left turn\n",
    "        time.sleep(0.5)\n",
    "        car.steering = 0.0   # Back to straight\n",
    "        print(\"  ✅ Calibrated steering test complete\")\n",
    "        \n",
    "        print(\"  Testing throttle (gentle)...\")\n",
    "        car.throttle = 1\n",
    "        time.sleep(0.3)\n",
    "        car.throttle = 0.0\n",
    "        print(\"  ✅ Throttle test complete\")\n",
    "        \n",
    "        car_ok = True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Car test failed: {e}\")\n",
    "    \n",
    "    if camera_ok and car_ok:\n",
    "        print(\"\\n✅ ALL HARDWARE TESTS PASSED!\")\n",
    "        print(\"🚀 Your calibrated JetRacer is ready for autonomous driving!\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"\\n❌ Hardware tests failed - fix issues before driving\")\n",
    "        return False\n",
    "\n",
    "def start_autonomous_driving():\n",
    "    \"\"\"Main autonomous driving function using your working camera code\"\"\"\n",
    "    print(\"\\n🏁 STARTING AUTONOMOUS DRIVING!\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Load model\n",
    "    model = load_trained_model()\n",
    "    if model is None:\n",
    "        print(\"❌ Cannot drive without model!\")\n",
    "        return\n",
    "    \n",
    "    print(\"⚠️  SAFETY REMINDERS:\")\n",
    "    print(\"   • Keep manual override ready!\")\n",
    "    print(\"   • Clear track with good lighting\")\n",
    "    print(\"   • Be ready to catch the car\")\n",
    "    print(\"   • Press Ctrl+C to stop\")\n",
    "    print(f\"   • Using your calibrated steering (offset = 0.17)\")\n",
    "    print(f\"   • Starting with SLOW throttle: {DrivingParams.THROTTLE}\")\n",
    "    \n",
    "    print(\"\\n⏱️  Starting in 5 seconds...\")\n",
    "    for i in range(5, 0, -1):\n",
    "        print(f\"   {i}...\")\n",
    "        time.sleep(1)\n",
    "    \n",
    "    print(\"🚀 GO!\")\n",
    "    \n",
    "    # Initialize hardware using YOUR working methods\n",
    "    camera = initialize_camera()\n",
    "    car = NvidiaRacecar()  # Uses your 0.17 offset automatically\n",
    "    \n",
    "    if camera is None:\n",
    "        print(\"❌ Camera failed to start!\")\n",
    "        return\n",
    "    \n",
    "    car.throttle = DrivingParams.THROTTLE\n",
    "    print(f\"🚗 Throttle set to {DrivingParams.THROTTLE}\")\n",
    "    print(f\"🎯 Using calibrated steering offset: {car.steering_offset}\")\n",
    "    \n",
    "    frame_count = 0\n",
    "    start_time = time.time()\n",
    "    steering_history = []\n",
    "    \n",
    "    try:\n",
    "        print(\"🎯 Autonomous driving active with your 371-image model...\")\n",
    "        \n",
    "        while True:\n",
    "            # Get camera image using YOUR working method\n",
    "            image = get_camera_image(camera)\n",
    "            if image is None:\n",
    "                print(\"⚠️ No image from camera\")\n",
    "                continue\n",
    "            \n",
    "            # AI prediction\n",
    "            processed_image = preprocess(image)\n",
    "            with torch.no_grad():\n",
    "                output = model(processed_image)\n",
    "                steering_prediction = float(output[0][0])  # AI's steering prediction\n",
    "            \n",
    "            # Apply AI steering parameters (on top of your hardware calibration)\n",
    "            ai_steering_command = (steering_prediction * DrivingParams.STEERING_GAIN + \n",
    "                                 DrivingParams.STEERING_BIAS)\n",
    "            \n",
    "            # Safety clamp\n",
    "            ai_steering_command = max(DrivingParams.MIN_STEERING, \n",
    "                                    min(DrivingParams.MAX_STEERING, ai_steering_command))\n",
    "            \n",
    "            # Send to your calibrated car (which adds the 0.17 offset automatically)\n",
    "            car.steering = ai_steering_command\n",
    "            \n",
    "            # Monitoring\n",
    "            frame_count += 1\n",
    "            steering_history.append(ai_steering_command)\n",
    "            \n",
    "            if frame_count % 50 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                fps = frame_count / elapsed\n",
    "                avg_steering = np.mean(steering_history[-50:])\n",
    "                print(f\"📊 Frame {frame_count} | FPS: {fps:.1f} | \"\n",
    "                      f\"AI Steering: {ai_steering_command:+.3f} | \"\n",
    "                      f\"Avg: {avg_steering:+.3f}\")\n",
    "            \n",
    "            time.sleep(DrivingParams.UPDATE_RATE)\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n🛑 STOPPING AUTONOMOUS DRIVING\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error during driving: {e}\")\n",
    "        \n",
    "    finally:\n",
    "        # Emergency stop\n",
    "        try:\n",
    "            car.throttle = 0.0\n",
    "            car.steering = 0.0\n",
    "            print(\"🛑 Car stopped safely\")\n",
    "        except:\n",
    "            print(\"⚠️ Error stopping car - use manual override!\")\n",
    "        \n",
    "        try:\n",
    "            if camera is not None:\n",
    "                camera.running = False\n",
    "            print(\"📷 Camera stopped\")\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Final stats\n",
    "        elapsed = time.time() - start_time\n",
    "        avg_fps = frame_count / elapsed if elapsed > 0 else 0\n",
    "        print(f\"📊 Final Stats: {frame_count} frames in {elapsed:.1f}s ({avg_fps:.1f} FPS)\")\n",
    "        \n",
    "        if steering_history:\n",
    "            avg_steering = np.mean(steering_history)\n",
    "            steering_range = max(steering_history) - min(steering_history)\n",
    "            print(f\"📊 AI Steering Stats: Avg={avg_steering:+.3f}, Range={steering_range:.3f}\")\n",
    "\n",
    "# Quick test function\n",
    "def quick_camera_test():\n",
    "    \"\"\"Quick test of your camera method\"\"\"\n",
    "    print(\"📷 Testing your camera method...\")\n",
    "    camera = initialize_camera()\n",
    "    if camera:\n",
    "        img = get_camera_image(camera)\n",
    "        if img is not None:\n",
    "            print(f\"✅ Camera test passed: {img.shape}\")\n",
    "        camera.running = False\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "print(\"\\n🎮 READY TO DRIVE WITH YOUR PROVEN METHODS!\")\n",
    "print(\"Functions available:\")\n",
    "print(\"  quick_camera_test() - Test your camera method\")\n",
    "print(\"  test_hardware() - Full hardware test\")\n",
    "print(\"  start_autonomous_driving() - GO RACING!\")\n",
    "\n",
    "print(f\"\\n⚙️ CURRENT SETTINGS:\")\n",
    "print(f\"   Camera: CSICamera(224x224, 21fps) - YOUR WORKING METHOD\")\n",
    "print(f\"   Hardware steering offset: 0.17 (your calibration)\")\n",
    "print(f\"   AI throttle: {DrivingParams.THROTTLE} (start slow!)\")\n",
    "print(f\"   AI steering gain: {DrivingParams.STEERING_GAIN}\")\n",
    "\n",
    "print(f\"\\n🏁 Your proven camera + calibrated hardware + 371-image model = READY!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fdb01c8-0ab5-40a9-94b5-f3d2b927acf7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'quick_steering_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mquick_steering_test\u001b[49m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'quick_steering_test' is not defined"
     ]
    }
   ],
   "source": [
    "quick_steering_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3744a406-219b-4946-9ba1-1bb386a64d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧪 TESTING HARDWARE\n",
      "==============================\n",
      "📷 Testing camera using your working method...\n",
      "🎬 Initializing camera using your working method...\n",
      "GST_ARGUS: Creating output stream\n",
      "CONSUMER: Waiting until producer is connected...\n",
      "GST_ARGUS: Available Sensor modes :\n",
      "GST_ARGUS: 3280 x 2464 FR = 21.000000 fps Duration = 47619048 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 3280 x 1848 FR = 28.000001 fps Duration = 35714284 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 1920 x 1080 FR = 29.999999 fps Duration = 33333334 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 1640 x 1232 FR = 29.999999 fps Duration = 33333334 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 1280 x 720 FR = 59.999999 fps Duration = 16666667 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: Running with following settings:\n",
      "   Camera index = 0 \n",
      "   Camera mode  = 4 \n",
      "   Output Stream W = 1280 H = 720 \n",
      "   seconds to Run    = 0 \n",
      "   Frame Rate = 59.999999 \n",
      "GST_ARGUS: Setup Complete, Starting captures for 0 seconds\n",
      "GST_ARGUS: Starting repeat capture requests.\n",
      "CONSUMER: Producer has connected; continuing.\n",
      "✅ Camera created and started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@16.466] global cap_gstreamer.cpp:1728 open OpenCV | GStreamer warning: Cannot query video position: status=0, value=-1, duration=-1\n"
     ]
    }
   ],
   "source": [
    "test_hardware()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69f2a89b-79f7-4652-84c3-6183ecb1eacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking camera properties\n",
      "width: 3280.0\n",
      "height: 2464.0\n",
      "fps: 21.0\n",
      "fourcc: 1448695129 (YUYV)\n",
      "\n",
      "trying to set MJPG format\n",
      "after setting - width: 3280.0, height: 2464.0\n",
      "fourcc: 1448695129 (YUYV)\n",
      "\n",
      "frame info:\n",
      "shape: (2464, 3280, 3)\n",
      "dtype: uint8\n",
      "min val: 0\n",
      "max val: 154\n",
      "mean values per channel: [  0. 154.   0.]\n",
      "channel means - B: 0.0, G: 154.0, R: 0.0\n",
      "saved debug_frame.jpg\n",
      "\n",
      "trying format conversions:\n",
      "saved yuv_converted.jpg\n",
      "saved rgb_swapped.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# check what format the camera is actually using\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if cap.isOpened():\n",
    "    print(\"checking camera properties\")\n",
    "    \n",
    "    # check what format opencv thinks its using\n",
    "    width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    fourcc = cap.get(cv2.CAP_PROP_FOURCC)\n",
    "    \n",
    "    print(f\"width: {width}\")\n",
    "    print(f\"height: {height}\")\n",
    "    print(f\"fps: {fps}\")\n",
    "    print(f\"fourcc: {int(fourcc)} ({chr(int(fourcc) & 0xFF)}{chr((int(fourcc) >> 8) & 0xFF)}{chr((int(fourcc) >> 16) & 0xFF)}{chr((int(fourcc) >> 24) & 0xFF)})\")\n",
    "    \n",
    "    # try to set a specific format\n",
    "    print(\"\\ntrying to set MJPG format\")\n",
    "    cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc('M','J','P','G'))\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "    \n",
    "    # check if it worked\n",
    "    width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    fourcc = cap.get(cv2.CAP_PROP_FOURCC)\n",
    "    print(f\"after setting - width: {width}, height: {height}\")\n",
    "    print(f\"fourcc: {int(fourcc)} ({chr(int(fourcc) & 0xFF)}{chr((int(fourcc) >> 8) & 0xFF)}{chr((int(fourcc) >> 16) & 0xFF)}{chr((int(fourcc) >> 24) & 0xFF)})\")\n",
    "    \n",
    "    # capture and check the image\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        print(f\"\\nframe info:\")\n",
    "        print(f\"shape: {frame.shape}\")\n",
    "        print(f\"dtype: {frame.dtype}\")\n",
    "        print(f\"min val: {frame.min()}\")\n",
    "        print(f\"max val: {frame.max()}\")\n",
    "        print(f\"mean values per channel: {frame.mean(axis=(0,1))}\")\n",
    "        \n",
    "        # check if all channels are the same (would indicate wrong format)\n",
    "        if len(frame.shape) == 3:\n",
    "            b_mean = frame[:,:,0].mean()\n",
    "            g_mean = frame[:,:,1].mean()\n",
    "            r_mean = frame[:,:,2].mean()\n",
    "            print(f\"channel means - B: {b_mean:.1f}, G: {g_mean:.1f}, R: {r_mean:.1f}\")\n",
    "            \n",
    "            if abs(b_mean - g_mean) < 1 and abs(g_mean - r_mean) < 1:\n",
    "                print(\"all channels same - probably grayscale in wrong format\")\n",
    "            \n",
    "        # save it\n",
    "        cv2.imwrite(\"debug_frame.jpg\", frame)\n",
    "        print(\"saved debug_frame.jpg\")\n",
    "        \n",
    "        # try converting from different formats\n",
    "        print(\"\\ntrying format conversions:\")\n",
    "        \n",
    "        # if its yuv or something\n",
    "        try:\n",
    "            yuv_converted = cv2.cvtColor(frame, cv2.COLOR_YUV2BGR)\n",
    "            cv2.imwrite(\"yuv_converted.jpg\", yuv_converted)\n",
    "            print(\"saved yuv_converted.jpg\")\n",
    "        except:\n",
    "            print(\"yuv conversion failed\")\n",
    "            \n",
    "        # if its rgb instead of bgr\n",
    "        try:\n",
    "            rgb_swapped = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "            cv2.imwrite(\"rgb_swapped.jpg\", rgb_swapped)\n",
    "            print(\"saved rgb_swapped.jpg\")\n",
    "        except:\n",
    "            print(\"rgb swap failed\")\n",
    "    \n",
    "    cap.release()\n",
    "else:\n",
    "    print(\"camera wont open\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb1b44af-1fc0-483f-8c32-6431efd0677e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jetcam imported ok\n",
      "jetcam failed: Could not initialize camera.  Please see error trace.\n",
      "trying to kill camera processes...\n",
      "trying jetcam again...\n",
      "jetcam retry failed: Could not initialize camera.  Please see error trace.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "# test the jetcam method that used to work\n",
    "try:\n",
    "    from jetcam.csi_camera import CSICamera\n",
    "    print(\"jetcam imported ok\")\n",
    "    \n",
    "    # try the exact settings from your working code\n",
    "    camera = CSICamera(width=224, height=224, capture_fps=21)\n",
    "    print(\"camera created\")\n",
    "    \n",
    "    camera.running = True\n",
    "    print(\"camera started, waiting...\")\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # test capture\n",
    "    for i in range(3):\n",
    "        img = camera.value\n",
    "        if img is not None:\n",
    "            print(f\"jetcam frame {i}: {img.shape}\")\n",
    "            cv2.imwrite(f\"jetcam_frame_{i}.jpg\", img)\n",
    "        else:\n",
    "            print(f\"jetcam frame {i}: None\")\n",
    "        time.sleep(1)\n",
    "    \n",
    "    camera.running = False\n",
    "    print(\"jetcam test done\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"jetcam failed: {e}\")\n",
    "    \n",
    "    # if jetcam fails, maybe we need to kill existing processes\n",
    "    print(\"trying to kill camera processes...\")\n",
    "    import subprocess\n",
    "    subprocess.run(['sudo', 'pkill', '-f', 'gst'], capture_output=True)\n",
    "    subprocess.run(['sudo', 'pkill', '-f', 'nvargus'], capture_output=True)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    print(\"trying jetcam again...\")\n",
    "    try:\n",
    "        camera = CSICamera(width=640, height=480, capture_fps=21)\n",
    "        camera.running = True\n",
    "        time.sleep(3)\n",
    "        \n",
    "        img = camera.value\n",
    "        if img is not None:\n",
    "            print(f\"jetcam retry worked: {img.shape}\")\n",
    "            cv2.imwrite(\"jetcam_retry.jpg\", img)\n",
    "        \n",
    "        camera.running = False\n",
    "    except Exception as e2:\n",
    "        print(f\"jetcam retry failed: {e2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b52a876d-e622-4466-9489-cc6fa2bd4dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capture 1: (480, 640, 3)\n",
      "capture 2: (480, 640, 3)\n",
      "capture 3: (480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "class AutonomousRacecarCamera:\n",
    "    def __init__(self, mode='inference', width=640, height=480, fps=21):\n",
    "        self.mode = mode\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.fps = fps\n",
    "        \n",
    "        if mode in ['inference', 'training']:\n",
    "            self.target_size = (224, 224)\n",
    "        else:\n",
    "            self.target_size = (width, height)\n",
    "            \n",
    "        self.running = False\n",
    "        self.last_image = None\n",
    "        \n",
    "    def start(self):\n",
    "        if self._test_camera():\n",
    "            self.running = True\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def _test_camera(self):\n",
    "        cmd = [\n",
    "            'gst-launch-1.0',\n",
    "            'nvarguscamerasrc', 'num-buffers=1',\n",
    "            '!', f'video/x-raw(memory:NVMM),width={self.width},height={self.height}',\n",
    "            '!', 'nvvidconv',\n",
    "            '!', 'jpegenc',\n",
    "            '!', 'filesink', 'location=/tmp/test_camera.jpg'\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            result = subprocess.run(cmd, capture_output=True, timeout=10)\n",
    "            return result.returncode == 0 and os.path.exists('/tmp/test_camera.jpg')\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    def read(self):\n",
    "        if not self.running:\n",
    "            return self.last_image\n",
    "        \n",
    "        temp_file = f\"/tmp/camera_frame_{int(time.time() * 1000)}.jpg\"\n",
    "        \n",
    "        cmd = [\n",
    "            'gst-launch-1.0',\n",
    "            'nvarguscamerasrc', 'num-buffers=1',\n",
    "            '!', f'video/x-raw(memory:NVMM),width={self.width},height={self.height}',\n",
    "            '!', 'nvvidconv',\n",
    "            '!', 'jpegenc',\n",
    "            '!', 'filesink', f'location={temp_file}'\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            result = subprocess.run(cmd, capture_output=True, timeout=5)\n",
    "            \n",
    "            if result.returncode == 0 and os.path.exists(temp_file):\n",
    "                img = cv2.imread(temp_file)\n",
    "                os.remove(temp_file)\n",
    "                \n",
    "                if img is not None:\n",
    "                    resized = cv2.resize(img, self.target_size)\n",
    "                    self.last_image = resized\n",
    "                    return resized\n",
    "            \n",
    "            return self.last_image\n",
    "            \n",
    "        except Exception as e:\n",
    "            return self.last_image\n",
    "    \n",
    "    def stop(self):\n",
    "        self.running = False\n",
    "    \n",
    "    @property\n",
    "    def value(self):\n",
    "        return self.read()\n",
    "    \n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self.target_size\n",
    "    \n",
    "    def capture_image(self, filepath):\n",
    "        img = self.read()\n",
    "        if img is not None:\n",
    "            cv2.imwrite(filepath, img)\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def __enter__(self):\n",
    "        self.start()\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, *args):\n",
    "        self.stop()\n",
    "\n",
    "def create_inference_camera():\n",
    "    return AutonomousRacecarCamera('inference')\n",
    "\n",
    "def create_training_camera():\n",
    "    return AutonomousRacecarCamera('training')\n",
    "\n",
    "def create_debug_camera():\n",
    "    return AutonomousRacecarCamera('debug')\n",
    "\n",
    "def test_camera(mode='debug'):\n",
    "    camera = AutonomousRacecarCamera(mode)\n",
    "    if camera.start():\n",
    "        for i in range(3):\n",
    "            img = camera.read()\n",
    "            if img is not None:\n",
    "                print(f\"capture {i+1}: {img.shape}\")\n",
    "                cv2.imwrite(f\"test_frame_{i}.jpg\", img)\n",
    "            time.sleep(0.5)\n",
    "        camera.stop()\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def quick_camera_test():\n",
    "    return test_camera('debug')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_camera()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17bb3d8e-fb0b-4e3f-b3c6-0fb1daa60f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing simple color fixes\n",
      "testing normal\n",
      "  created 0 bytes\n",
      "testing wb_auto\n",
      "  created 0 bytes\n",
      "testing wb_off\n",
      "  created 0 bytes\n",
      "testing less_saturation\n",
      "  created 0 bytes\n",
      "\n",
      "trying software color correction\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 113\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtesting simple color fixes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    112\u001b[0m test_simple_fixes()\n\u001b[0;32m--> 113\u001b[0m \u001b[43mfix_yellow_in_software\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mcheck the simple_*.jpg and corrected_*.jpg files\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 69\u001b[0m, in \u001b[0;36mfix_yellow_in_software\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(temp_file)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# try different color corrections\u001b[39;00m\n\u001b[1;32m     67\u001b[0m corrections \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     68\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal\u001b[39m\u001b[38;5;124m'\u001b[39m, img),\n\u001b[0;32m---> 69\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mless_yellow\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mreduce_yellow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m),\n\u001b[1;32m     70\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhite_balance\u001b[39m\u001b[38;5;124m'\u001b[39m, auto_white_balance(img)),\n\u001b[1;32m     71\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma_fix\u001b[39m\u001b[38;5;124m'\u001b[39m, gamma_correction(img, \u001b[38;5;241m0.8\u001b[39m)),\n\u001b[1;32m     72\u001b[0m ]\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, corrected \u001b[38;5;129;01min\u001b[39;00m corrections:\n\u001b[1;32m     75\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorrected_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, corrected)\n",
      "Cell \u001b[0;32mIn[12], line 80\u001b[0m, in \u001b[0;36mreduce_yellow\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreduce_yellow\u001b[39m(img):\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# reduce yellow tint by lowering red and green channels slightly\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     corrected \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m()\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     81\u001b[0m     corrected[:,:,\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.9\u001b[39m  \u001b[38;5;66;03m# reduce green\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     corrected[:,:,\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.9\u001b[39m  \u001b[38;5;66;03m# reduce red\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'copy'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacc49d6-6fd4-4e27-b21c-003f2dd071df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
